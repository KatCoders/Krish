import os
import io
import time
import tempfile
import requests
import streamlit as st
import logging
from typing import Optional
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from gtts import gTTS

# Langchain / Groq imports
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ------------------- Logging Setup -------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ------------------- Load Environment Variables -------------------
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()

# Validation
if not GROQ_API_KEY:
    st.error("‚ùå .env ‡§´‡§º‡§æ‡§á‡§≤ ‡§Æ‡•á‡§Ç `GROQ_API_KEY` ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç")
    st.info("üí° Groq API key: https://console.groq.com")
    st.stop()

# Initialize OpenAI client
openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# ------------------- Unified TTS System -------------------
class UnifiedTTSSystem:
    """Unified TTS with OpenAI primary and gTTS fallback"""
    
    def __init__(self):
        self.openai_available = openai_client is not None
        self.cache = {}
        
    def generate_audio(self, text: str, use_cache: bool = True) -> Optional[bytes]:
        """Generate audio with fallback"""
        if not text or not text.strip():
            return None
        
        # Truncate long text
        if len(text) > 500:
            text = self._truncate_intelligently(text, 500)
        
        # Check cache
        text_hash = hash(text[:500])
        if use_cache and text_hash in self.cache:
            logger.info("Using cached audio")
            return self.cache[text_hash]
        
        # Try OpenAI first
        if self.openai_available:
            audio_bytes = self._openai_tts(text)
            if audio_bytes:
                if use_cache and len(self.cache) < 20:
                    self.cache[text_hash] = audio_bytes
                return audio_bytes
            logger.warning("OpenAI TTS failed, using gTTS")
        
        # Fallback to gTTS
        audio_bytes = self._gtts_tts(text)
        if audio_bytes and use_cache and len(self.cache) < 20:
            self.cache[text_hash] = audio_bytes
        return audio_bytes
    
    def _openai_tts(self, text: str) -> Optional[bytes]:
        """OpenAI TTS implementation"""
        try:
            response = openai_client.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=text[:4096]
            )
            return response.read()
        except Exception as e:
            logger.error(f"OpenAI TTS error: {e}")
            return None
    
    def _gtts_tts(self, text: str) -> Optional[bytes]:
        """gTTS fallback"""
        try:
            tts = gTTS(text=text, lang="hi", slow=False)
            audio_buffer = io.BytesIO()
            tts.write_to_fp(audio_buffer)
            audio_buffer.seek(0)
            return audio_buffer.getvalue()
        except Exception as e:
            logger.error(f"gTTS error: {e}")
            return None
    
    def _truncate_intelligently(self, text: str, max_length: int) -> str:
        """Truncate at sentence boundaries"""
        if len(text) <= max_length:
            return text
        
        sentences = text.split('‡•§')
        truncated = ""
        for sentence in sentences:
            if len(truncated + sentence + "‡•§") <= max_length:
                truncated += sentence + "‡•§"
            else:
                break
        
        return truncated if truncated else text[:max_length] + "..."

# ------------------- Speech-to-Text -------------------
class SpeechToText:
    """STT using Groq Whisper API"""
    
    @staticmethod
    def transcribe_audio(file_path: str, language: str = "hi") -> str:
        """Transcribe audio file"""
        if not os.path.exists(file_path):
            logger.error(f"Audio file not found: {file_path}")
            return ""
        
        try:
            url = "https://api.groq.com/openai/v1/audio/transcriptions"
            headers = {"Authorization": f"Bearer {GROQ_API_KEY}"}
            
            with open(file_path, "rb") as audio_file:
                files = {"file": (os.path.basename(file_path), audio_file, "audio/wav")}
                data = {
                    "model": "whisper-large-v3-turbo",
                    "language": "hi",
                    "response_format": "text"
                }
                response = requests.post(url, headers=headers, data=data, files=files, timeout=45)
            
            response.raise_for_status()
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"Transcription error: {e}")
            return ""



# ------------------- Session State -------------------
def init_session_state():
    """Initialize session state"""
    if "initialized" not in st.session_state:
        st.session_state.update({
            "initialized": True,
            "chat_history": [],
            "processing": False,
            "last_audio": None,
            "tts_system": UnifiedTTSSystem(),
            "stt": SpeechToText(),
            # Mock data for demo
            "city": "‡§á‡§Ç‡§¶‡•å‡§∞",
            "weather_data": {"temperature": 28, "humidity": 65},
            "soil_data": {"ph": 6.5, "nitrogen": 45},
            "predicted_crop": "‡§ó‡•á‡§π‡•Ç‡§Ç",
            "confidence": 85.5
        })

init_session_state()


# ------------------- LLM Setup -------------------
try:
    MODEL_NAME = "llama-3.3-70b-versatile"
    llm = ChatGroq(
        groq_api_key=GROQ_API_KEY,
        model_name=MODEL_NAME,
        temperature=0.7,
        streaming=True,
        max_tokens=1024
    )

    # Enhanced prompt template with context
    template_text = """
‡§Ü‡§™ ‡§è‡§ï ‡§Ö‡§®‡•Å‡§≠‡§µ‡•Ä ‡§î‡§∞ ‡§¶‡•ã‡§∏‡•ç‡§§‡§æ‡§®‡§æ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§Æ‡§ø‡§§‡•ç‡§∞ ‡§π‡•à‡§Ç ‡§ú‡•ã ‡§ï‡•É‡§∑‡§ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞ ‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§ 
Agar koi aap se puche apko kisne banaya, to kaho "AgroMind team ne, jo aapke kisan bhaiyon ke liye best AI assistant banane mein laga hai".

‡§Ü‡§™‡§ï‡•Ä ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ‡§è‡§Ç:
- ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∏‡§∞‡§≤, ‡§∏‡§Æ‡§ù‡§®‡•á ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡§æ
- ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§™‡§∞‡§ø‡§∏‡•ç‡§•‡§ø‡§§‡§ø‡§Ø‡•ã‡§Ç (‡§Æ‡•å‡§∏‡§Æ, ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä) ‡§ï‡•á ‡§Ö‡§®‡•Å‡§∏‡§æ‡§∞ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§∏‡§≤‡§æ‡§π ‡§¶‡•á‡§®‡§æ  
- "‡§≠‡§æ‡§à", "‡§ú‡•Ä", "‡§Ü‡§á‡§è" ‡§ú‡•à‡§∏‡•á ‡§¶‡•ã‡§∏‡•ç‡§§‡§æ‡§®‡§æ ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡§æ
- ‡§õ‡•ã‡§ü‡•á, actionable steps ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡§æ





‡§®‡§ø‡§Ø‡§Æ:
1. ‡§Ø‡§¶‡§ø ‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü ‡§∞‡•á‡§ü/‡§Æ‡§Ç‡§°‡•Ä ‡§≠‡§æ‡§µ ‡§™‡•Ç‡§õ‡•á‡§Ç ‡§§‡•ã ‡§ï‡§π‡•á‡§Ç: "‡§Ø‡§π ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§Ö‡§≠‡•Ä ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§Æ‡•á‡§Ç ‡§π‡•à, ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•ã‡§ó‡•Ä"
2. ‡§´‡§∏‡§≤ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ä‡§™‡§∞ ‡§¶‡§ø‡§è ‡§ó‡§è ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§°‡•á‡§ü‡§æ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
3. ‡§π‡§Æ‡•á‡§∂‡§æ ‡§™‡•ç‡§∞‡•à‡§ï‡•ç‡§ü‡§ø‡§ï‡§≤ ‡§î‡§∞ ‡§≤‡§æ‡§ó‡•Ç ‡§ï‡§∞‡§®‡•á ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§∏‡§≤‡§æ‡§π ‡§¶‡•á‡§Ç
4. ‡§Ö‡§ó‡§∞ ‡§ï‡•ã‡§à ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§∏‡§≤‡§æ‡§π ‡§™‡•Ç‡§õ‡•á ‡§§‡•ã ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§Æ‡§ø‡§≤‡§®‡•á ‡§ï‡•ã ‡§ï‡§π‡•á‡§Ç
Aur jis salwal ka jawab aapko nahi pata, usme aap seedha "‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•á‡§¶ ‡§π‡•à, ‡§Æ‡•à‡§Ç ‡§á‡§∏ ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§∏‡§ï‡§§‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§" keh dena.

‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§ï‡§æ ‡§∏‡§µ‡§æ‡§≤: {question}
"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", template_text),
        ("user", "{question}")
    ])
    chain = prompt | llm | StrOutputParser()
    
except Exception as e:
    st.error(f"‚ùå LLM ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§° ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ: {e}")
    st.info("‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•Ä ‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§ï‡§®‡•á‡§ï‡•ç‡§∂‡§® ‡§î‡§∞ GROQ_API_KEY ‡§ï‡•Ä ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡§∞‡•á‡§Ç")
    st.stop()
# ------------------- LLM Response Function -------------------
def get_llm_response(user_question: str) -> str:
    """Generate LLM response"""
    if not user_question.strip():
        return "‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡§µ‡§æ‡§≤ ‡§≤‡§ø‡§ñ‡•á‡§Ç‡•§"
    
    try:
        full_response = ""
        response_placeholder = st.empty()
        
        for chunk in chain.stream({
            "question": user_question,
            "location": st.session_state.city,
            "temperature": st.session_state.weather_data['temperature'],
            "humidity": st.session_state.weather_data['humidity'],
            "soil_ph": st.session_state.soil_data['ph'],
            "nitrogen": st.session_state.soil_data['nitrogen'],
            "crop_suggestion": st.session_state.predicted_crop,
            "confidence": st.session_state.confidence
        }):
            full_response += chunk
            response_placeholder.markdown(f"**ü§ñ ‡§ú‡§µ‡§æ‡§¨:** {full_response}‚ñå")
        
        response_placeholder.markdown(f"**ü§ñ ‡§ú‡§µ‡§æ‡§¨:** {full_response}")
        
        st.session_state.chat_history.append({
            "role": "assistant",
            "content": full_response,
            "timestamp": datetime.now().isoformat()
        })
        
        return full_response
        
    except Exception as e:
        logger.error(f"LLM error: {e}")
        return "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§ú‡§µ‡§æ‡§¨ ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§™‡§æ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§"

# ------------------- Voice Input Section -------------------

