import os
import io
import time
import json
import tempfile
import requests
import numpy as np
import pandas as pd
import streamlit as st
import logging
from PIL import Image
from typing import Optional, Tuple, Dict, Any
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
from gtts import gTTS
from voice_pipeline import *
from st_audiorec import st_audiorec
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from voiceassit import voice_input_component
import streamlit.components.v1 as components
from streamlit_geolocation import streamlit_geolocation 
from auth import google_login
from llm import *
# Langchain / Groq imports
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ------------------- Logging Setup -------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ------------------- Load environment variables -------------------
load_dotenv()
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY", "").strip()
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "").strip()

# Data.gov.in API Configuration

# ------------------- Page config & Enhanced CSS -------------------
st.set_page_config(
    page_title="ЁЯМ╛ Krish AI рдХреГрд╖рд┐ рд╕рд╣рд╛рдпрдХ", 
    layout="wide", 
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "Krish AIрдХреГрд╖рд┐ рд╕рд╣рд╛рдпрдХ - рдЖрдкрдХрд╛ рдбрд┐рдЬрд┐рдЯрд▓ рдЦреЗрддреА рд╕рд▓рд╛рд╣рдХрд╛рд░"
    }
)

st.markdown("""
<style>
    .main-title { 
        text-align: center; 
        color: #2E8B57; 
        font-size: 2.2rem; 
        margin-bottom: 1rem; 
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .location-prompt {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 3rem;
        border-radius: 20px;
        text-align: center;
        color: white;
        margin: 2rem auto;
        max-width: 600px;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
    }
    .location-prompt h2 {
        font-size: 2rem;
        margin-bottom: 1rem;
    }
    .location-prompt p {
        font-size: 1.1rem;
        margin-bottom: 1.5rem;
        opacity: 0.9;
    }
    .location-icon {
        font-size: 4rem;
        margin-bottom: 1rem;
        animation: pulse 2s infinite;
    }
    @keyframes pulse {
        0%, 100% { transform: scale(1); }
        50% { transform: scale(1.1); }
    }
    .voice-section { 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
        padding: 1.5rem; 
        border-radius: 12px; 
        color: white; 
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .chat-container {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #28a745;
    }
    .user-message {
        background-color: #e3f2fd;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 3px solid #2196f3;
    }
    .assistant-message {
        background-color: #f1f8e9;
        padding: 0.8rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        border-left: 3px solid #4caf50;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    .price-card {
        background: linear-gradient(135deg, #4CAF50 0%, #45a049 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)
# ------------------- Authentication Check -------------------




# ------------------- Session state initialization -------------------
def init_session_state():
    """Initialize all session state variables"""
    if "app_initialized" not in st.session_state:
        st.session_state.update({
            "app_initialized": False,
            "location_granted": False,
            "tts_system_ready": False,
            "stt_warmed": False,
            "chat_history": [],
            "processing": False,
            "last_audio_data": None,
            "last_audio": None,
            "voice_enabled": True,
            "auto_play_response": True,
            "use_offline_tts": False,
            "location_method": "ip",
            "client_location": None,
            "warmup_status": "рдкреНрд░рд╛рд░рдВрдн рдХрд░ рд░рд╣реЗ рд╣реИрдВ...",
            "tts_system": UnifiedTTSSystem(),
            "stt": SpeechToText(),
            "user_lat": None,
            "user_lon": None,
            "user_city": None,
            "market_data_loaded": False
        })

init_session_state()

# ------------------- Location Request Screen -------------------
def show_location_request_screen():
    """Display location permission request screen"""
    st.markdown('<h1 class="main-title">ЁЯМ╛ KRISH AI рдЖрдзрд╛рд░рд┐рдд рдлрд╕рд▓ рд╕рд▓рд╛рд╣ рд╕рд╣рд╛рдпрдХ</h1>', unsafe_allow_html=True)
    col1, col2, col3 = st.columns([2, 3, 1])
    with col1:
        pass
    with col3:
        pass
    with col2:
        st.markdown("<h5><b>рдХреГрдкрдпрд╛ рдЗрд╕ рд▓реЛрдЧреЛ рдкрд░ рдХреНрд▓рд┐рдХ рдХрд░реЗрдВ</b></h5>", unsafe_allow_html=True)
        loc = streamlit_geolocation()
    st.markdown("""
    <div class="location-prompt">
        <div class="location-icon">ЁЯУН</div>
        <h2>рд╕реНрдерд╛рди рдХреА рдЕрдиреБрдорддрд┐ рдЪрд╛рд╣рд┐рдП</h2>
        <p>рдЖрдкрдХреА рд╕рдЯреАрдХ рдХреГрд╖рд┐ рд╕рд▓рд╛рд╣ рдХреЗ рд▓рд┐рдП рд╣рдореЗрдВ рдЖрдкрдХреЗ рд╕реНрдерд╛рди рдХреА рдЬрд░реВрд░рдд рд╣реИред</p>
        <p style="font-size: 0.9rem;">
            тЬЕ рдореМрд╕рдо рдЖрдзрд╛рд░рд┐рдд рд╕рд▓рд╛рд╣<br>
            тЬЕ рд╕реНрдерд╛рдиреАрдп рдорд┐рдЯреНрдЯреА рдХреА рдЬрд╛рдирдХрд╛рд░реА<br>
            тЬЕ рдХреНрд╖реЗрддреНрд░реАрдп рдлрд╕рд▓ рд╕реБрдЭрд╛рд╡<br>
            тЬЕ рдордВрдбреА рднрд╛рд╡ рдХреА рдЬрд╛рдирдХрд╛рд░реА
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    if loc and isinstance(loc, dict):
        lat = loc.get("latitude")
        lon = loc.get("longitude")
        
        if lat is not None and lon is not None:
            st.session_state.user_lat = lat
            st.session_state.user_lon = lon
            st.session_state.location_granted = True
            
            try:
                response = requests.get(
                    "https://nominatim.openstreetmap.org/reverse",
                    params={
                        "lat": lat,
                        "lon": lon,
                        "format": "json",
                        "accept-language": "hi"
                    },
                    headers={"User-Agent": "AgroMind-App/1.0"},
                    timeout=5
                )
                if response.status_code == 200:
                    data = response.json()
                    address = data.get("address", {})
                    city = (address.get("city") or 
                           address.get("town") or 
                           address.get("village") or 
                           address.get("state_district") or
                           "рдЖрдкрдХрд╛ рд╕реНрдерд╛рди")
                    st.session_state.user_city = f"ЁЯУН {city}"
            except:
                st.session_state.user_city = "ЁЯУН рдЖрдкрдХрд╛ рд╕реНрдерд╛рди (GPS)"
            
            st.success("тЬЕ рд╕реНрдерд╛рди рдкреНрд░рд╛рдкреНрдд рд╣реЛ рдЧрдпрд╛! рдРрдк рд▓реЛрдб рд╣реЛ рд░рд╣рд╛ рд╣реИ...")
            time.sleep(1)
            st.rerun()
    else:
        st.info("ЁЯСЖ рдХреГрдкрдпрд╛ рдЕрдкрдиреЗ рдмреНрд░рд╛рдЙрдЬрд╝рд░ рдореЗрдВ рд╕реНрдерд╛рди рдХреА рдЕрдиреБрдорддрд┐ рджреЗрдВ")
        
        st.markdown("---")
        st.markdown("### рдпрд╛")
        
        if st.button("ЁЯМР IP рдЖрдзрд╛рд░рд┐рдд рд╕реНрдерд╛рди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ", type="secondary"):
            try:
                response = requests.get("https://ipinfo.io/json", timeout=8)
                if response.status_code == 200:
                    data = response.json()
                    loc_str = data.get("loc", "28.61,77.20").split(",")
                    city = data.get("city", "рджрд┐рд▓реНрд▓реА")
                    region = data.get("region", "")
                    
                    st.session_state.user_lat = float(loc_str[0])
                    st.session_state.user_lon = float(loc_str[1])
                    st.session_state.user_city = f"ЁЯМР {city}, {region} (IP)"
                    st.session_state.location_granted = True
                    
                    st.success("тЬЕ IP рдЖрдзрд╛рд░рд┐рдд рд╕реНрдерд╛рди рдкреНрд░рд╛рдкреНрдд рд╣реЛ рдЧрдпрд╛!")
                    time.sleep(1)
                    st.rerun()
            except Exception as e:
                st.error(f"тЭМ рд╕реНрдерд╛рди рдкреНрд░рд╛рдкреНрдд рдирд╣реАрдВ рд╣реЛ рд╕рдХрд╛: {str(e)}")

if not st.session_state.location_granted:
    show_location_request_screen()
    st.stop()

# ------------------- Main App -------------------
lat = st.session_state.user_lat
lon = st.session_state.user_lon
city = st.session_state.user_city

st.markdown('<h2 class="main-title">ЁЯМ╛ KRISH AI рдЖрдзрд╛рд░рд┐рдд рдлрд╕рд▓ рд╕рд▓рд╛рд╣ рд╕рд╣рд╛рдпрдХ (рд╣рд┐рдВрджреА, рдЖрд╡рд╛рдЬрд╝ рд╕рд╣рд┐рдд)</h2>', unsafe_allow_html=True)

# ------------------- Enhanced utility functions -------------------
def get_default_soil_data() -> Dict[str, float]:
    return {"ph": 6.5, "nitrogen": 50, "organic_carbon": 10, "sand": 40, "silt": 40, "clay": 20}

def get_default_weather_data() -> Dict[str, Any]:
    return {"temperature": 25, "humidity": 70, "precipitation": 2, "wind_speed": 10, "condition": "рд╕рд╛рдлрд╝"}

@st.cache_data(ttl=3600, show_spinner=False)
def fetch_soil(lat: float, lon: float) -> Dict[str, float]:
    try:
        url = "https://rest.isric.org/soilgrids/v2.0/properties"
        params = {"lon": lon, "lat": lat, "property": "phh2o", "depth": "0-5cm", "value": "mean"}
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            base_soil = get_default_soil_data()
            lat_factor = (lat - 20) / 20
            base_soil["ph"] += lat_factor * 0.5
            base_soil["nitrogen"] += lat_factor * 10
            return base_soil
    except Exception as e:
        logger.error(f"Soil data fetch error: {e}")
    return get_default_soil_data()

@st.cache_data(ttl=600, show_spinner=False)
def fetch_weather(lat: float, lon: float) -> Dict[str, Any]:
    if not WEATHER_API_KEY:
        return get_default_weather_data()
    try:
        url = "http://api.weatherapi.com/v1/current.json"
        params = {"key": WEATHER_API_KEY, "q": f"{lat},{lon}", "aqi": "no"}
        response = requests.get(url, params=params, timeout=10)
        if response.status_code == 200:
            data = response.json()
            current = data.get("current", {})
            return {
                "temperature": current.get("temp_c", 25),
                "humidity": current.get("humidity", 70),
                "precipitation": current.get("precip_mm", 2),
                "wind_speed": current.get("wind_kph", 10),
                "condition": current.get("condition", {}).get("text", "рд╕рд╛рдлрд╝"),
                "feels_like": current.get("feelslike_c", 25),
                "uv": current.get("uv", 5)
            }
    except Exception as e:
        logger.error(f"Weather data fetch error: {e}")
    return get_default_weather_data()

@st.cache_resource(show_spinner=False)
def get_trained_model() -> Tuple[RandomForestClassifier, StandardScaler]:
    np.random.seed(42)
    n_samples = 2000
    features, labels = [], []
    
    for _ in range(n_samples):
        temp = np.random.normal(25, 10)
        humidity = np.random.normal(70, 20)
        ph = np.random.normal(6.5, 1.2)
        nitrogen = np.random.normal(50, 25)
        features.append([temp, humidity, ph, nitrogen])
        
        if temp < 22 and humidity > 55 and ph > 6.0:
            labels.append(0)
        elif temp > 28 and humidity > 75 and ph < 7.5:
            labels.append(1)
        elif temp > 20 and temp < 35 and humidity < 80:
            labels.append(2)
        else:
            labels.append(np.random.choice([0, 1, 2]))
    
    X = np.array(features)
    y = np.array(labels)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    clf = RandomForestClassifier(n_estimators=150, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)
    clf.fit(X_scaled, y)
    return clf, scaler

def get_crop_prediction(soil: Dict[str, float], weather: Dict[str, Any]) -> Tuple[str, float]:
    try:
        clf, scaler = get_trained_model()
        features = np.array([[
            weather.get("temperature", 25),
            weather.get("humidity", 70),
            soil.get("ph", 6.5),
            soil.get("nitrogen", 50)
        ]])
        features_scaled = scaler.transform(features)
        probabilities = clf.predict_proba(features_scaled)[0]
        prediction = int(clf.predict(features_scaled)[0])
        crop_map = {0: "ЁЯМ╛ рдЧреЗрд╣реВрдБ", 1: "ЁЯМ▒ рдзрд╛рди", 2: "ЁЯМ╜ рдордХреНрдХрд╛"}
        confidence = float(max(probabilities) * 100)
        return crop_map.get(prediction, "тЭУ рдЕрдЬреНрдЮрд╛рдд"), confidence
    except Exception as e:
        logger.error(f"Crop prediction failed: {e}")
        return "ЁЯМ╛ рдЧреЗрд╣реВрдБ", 75.0

def perform_comprehensive_warmup():
    if st.session_state.app_initialized:
        return True
    progress_container = st.container()
    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()
        warmup_steps = [
            ("ЁЯФз рд╕рд┐рд╕реНрдЯрдо рдкреНрд░рд╛рд░рдВрдн...", 20),
            ("ЁЯОд рдЖрд╡рд╛рдЬрд╝ рд╕рд┐рд╕реНрдЯрдо рддреИрдпрд╛рд░...", 50),
            ("ЁЯФК TTS рд╕рд┐рд╕реНрдЯрдо рд╡рд╛рд░реНрдо рдЕрдк...", 70),
            ("ЁЯУК рдордВрдбреА рдбреЗрдЯрд╛ рд▓реЛрдб...", 85),
            ("тЬЕ рддреИрдпрд╛рд░!", 100)
        ]
        for step_text, progress_value in warmup_steps:
            status_text.markdown(f'<div class="status-info">{step_text}</div>', unsafe_allow_html=True)
            progress_bar.progress(progress_value)
            time.sleep(0.3)
        time.sleep(0.5)
        progress_container.empty()
    st.session_state.app_initialized = True
    return True

perform_comprehensive_warmup()

# Load data
with st.spinner("ЁЯМН рдкрд░реНрдпрд╛рд╡рд░рдг рдбреЗрдЯрд╛ рд▓реЛрдб рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
    soil_data = fetch_soil(lat, lon)
    weather_data = fetch_weather(lat, lon)
   
        

# ------------------- Enhanced Groq LLM with Market Rate Tool -------------------

    
def process_text_input(user_input: str):
    if st.session_state.processing:
        st.warning("тП│ рдХреГрдкрдпрд╛ рдкреНрд░рддреАрдХреНрд╖рд╛ рдХрд░реЗрдВ...")
        return
    
    st.session_state.processing = True
    try:
        with st.chat_message("user"):
            st.markdown(f"тЬНя╕П {user_input}")
        
        st.session_state.chat_history.append({
            "role": "user", 
            "content": user_input, 
            "type": "text",
            "timestamp": datetime.now().isoformat()
        })
    
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            response_placeholder.markdown("ЁЯдЦ рд╕реЛрдЪ рд░рд╣рд╛ рд╣реВрдВ... ЁЯза")
            
            full_response = ""
            try:
                response = get_llm_response(user_input )
                full_response = response
                response_placeholder.markdown(f"ЁЯдЦ {full_response}")
                
                st.session_state.chat_history.append({
                    "role": "assistant",
                    "content": full_response,
                    "type": "text",
                    "timestamp": datetime.now().isoformat()
                })
                
            except Exception as e:
                error_msg = f"рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рдХрд░рдиреЗ рдореЗрдВ рд╕рдорд╕реНрдпрд╛: {str(e)}"
                response_placeholder.error(f"тЭМ {error_msg}")
                full_response = "рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, рддрдХрдиреАрдХреА рд╕рдорд╕реНрдпрд╛ рдХреЗ рдХрд╛рд░рдг рдЬрд╡рд╛рдм рдирд╣реАрдВ рджреЗ рд╕рдХрд╛ред"
                logger.error(f"LLM generation error: {e}")
        
        if st.session_state.voice_enabled and full_response:
            with st.spinner("ЁЯОз рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
                try:
                    audio_bytes = st.session_state.tts_system.generate_audio(full_response)
                    if audio_bytes:
                        st.audio(audio_bytes, format="audio/mp3")
                        st.success("ЁЯФК рддреИрдпрд╛рд░!")
                    else:
                        st.info("ЁЯТб рдЯреЗрдХреНрд╕реНрдЯ рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рд╣реИ")
                except Exception as tts_error:
                    logger.warning(f"TTS generation failed: {tts_error}")
                    st.info("ЁЯТб рдЯреЗрдХреНрд╕реНрдЯ рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рд╣реИ")

    except Exception as e:
        st.error(f"тЭМ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдореЗрдВ рд╕рдорд╕реНрдпрд╛: {str(e)}")
        logger.error(f"Text processing error: {e}")
    finally:
        st.session_state.processing = False

# ------------------- Tomato Disease Detection Section -------------------

with st.sidebar:
    st.header("ЁЯЪЬ Krish AI Menu")

    if st.button("ЁЯПб рд╣реЛрдо"):
        st.session_state.nav = "home"
        st.rerun()

    if st.button("ЁЯНЕ рдЯрдорд╛рдЯрд░ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ"):
        st.session_state.nav = "tomato"
        st.rerun()
    if st.button("ЁЯМ╛ рдлрд╕рд▓ рд╕рд▓рд╛рд╣ WhatsApp"):
        st.session_state.nav = "crop"
        st.rerun()

    st.markdown("---")

    st.subheader("ЁЯТм рдЪреИрдЯ рдЙрдкрдХрд░рдг")
    if st.button("тЩ╗я╕П рдЪреИрдЯ рд░реАрд╕реЗрдЯ"):
        st.session_state["chat_history"] = []
        st.success("тЬЕ рдЪреИрдЯ рд░реАрд╕реЗрдЯ рдХрд░ рджрд┐рдпрд╛ рдЧрдпрд╛!")

    # Export (kept simple)
    if st.button("ЁЯУе рдЪреИрдЯ рдПрдХреНрд╕рдкреЛрд░реНрдЯ"):
        chats = st.session_state.get("chat_history", [])
        if chats:
            export_data = {
                "timestamp": datetime.now().isoformat(),
                "location": st.session_state.get("user_city", "рдЕрдЬреНрдЮрд╛рдд"),
                "chat_history": chats
            }
            st.download_button(
                label="ЁЯТ╛ JSON рдбрд╛рдЙрдирд▓реЛрдб рдХрд░реЗрдВ",
                data=json.dumps(export_data, ensure_ascii=False, indent=2),
                file_name=f"krish_chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                key="dl_chat_json"
            )
        else:
            st.info("тЪая╕П рдХреЛрдИ рдЪреИрдЯ рд╣рд┐рд╕реНрдЯреНрд░реА рдЙрдкрд▓рдмреНрдз рдирд╣реАрдВ рд╣реИ")

    st.markdown("---")
    st.subheader("тЪЩя╕П рд╕реЗрдЯрд┐рдВрдЧреНрд╕")
    st.session_state["voice_enabled"] = st.checkbox(
        "ЁЯФК рдЖрд╡рд╛рдЬрд╝ рдЪрд╛рд▓реВ рдХрд░реЗрдВ",
        value=st.session_state.get("voice_enabled", True),
        key="voice_toggle",
    )

# ------------------- Voice Input Section -------------------
st.markdown("""
<style>
.chat-container {
    background-color: #000000;  
    color: #FFFFFF;           
    padding: 20px;
    border-radius: 15px;
    box-shadow: 0px 4px 10px rgba(0,0,0,0.5);
    margin-top: 20px;
    margin-bottom: 20px;
    font-family: 'Segoe UI', sans-serif;
}
.chat-container h4 {
    font-size: 1.8rem;
    margin-bottom: 10px;
    color: #00FF7F;
}
.chat-container ul li {
    margin-bottom: 5px;
}
.chat-container em {
    color: #FFD700;
}
</style>

<div class="chat-container">
    <h4>ЁЯСЛ рдирдорд╕реНрддреЗ рдХрд┐рд╕рд╛рди рднрд╛рдИ!</h4>
    <p>рдореИрдВ рдЖрдкрдХрд╛ AI рдХреГрд╖рд┐ рд╕рд▓рд╛рд╣рдХрд╛рд░ рд╣реВрдВред рдЖрдк рдореБрдЭрд╕реЗ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рд╡рд┐рд╖рдпреЛрдВ рдкрд░ рд╕рд╡рд╛рд▓ рдкреВрдЫ рд╕рдХрддреЗ рд╣реИрдВ:</p>
    <ul>
        <li>ЁЯМ╛ <strong>рдлрд╕рд▓ рдХреА рд╕рд┐рдлрд╛рд░рд┐рд╢</strong> - рдХреМрди рд╕реА рдлрд╕рд▓ рдмреЛрдПрдВ</li>
        <li>ЁЯМ▒ <strong>рдорд┐рдЯреНрдЯреА рдХреА рджреЗрдЦрднрд╛рд▓</strong> - рдорд┐рдЯреНрдЯреА рд╕реБрдзрд╛рд░ рдХреЗ рддрд░реАрдХреЗ</li>
        <li>ЁЯМзя╕П <strong>рдореМрд╕рдо рдЖрдзрд╛рд░рд┐рдд рд╕рд▓рд╛рд╣</strong> - рдореМрд╕рдо рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдЦреЗрддреА</li>
        <li>ЁЯРЫ <strong>рдХреАрдЯ рдФрд░ рд░реЛрдЧ рдирд┐рдпрдВрддреНрд░рдг</strong> - рд╕рдорд╕реНрдпрд╛рдУрдВ рдХрд╛ рд╕рдорд╛рдзрд╛рди</li>
        <li>ЁЯТз <strong>рд╕рд┐рдВрдЪрд╛рдИ рдкреНрд░рдмрдВрдзрди</strong> - рдкрд╛рдиреА рдХреА рд╕рд╣реА рд╡реНрдпрд╡рд╕реНрдерд╛</li>
        <li>ЁЯМ┐ <strong>рдЬреИрд╡рд┐рдХ рдЦреЗрддреА</strong> - рдкреНрд░рд╛рдХреГрддрд┐рдХ рддрд░реАрдХреЗ</li>
        <li>ЁЯТ░ <strong>рдордВрдбреА рднрд╛рд╡</strong> - рдлрд╕рд▓реЛрдВ рдХреА рдХреАрдордд рдЬрд╛рдиреЗрдВ (рдирдпрд╛!)</li>
    </ul>
    <p><em>рдЖрдк рдЯреЗрдХреНрд╕реНрдЯ рд▓рд┐рдЦрдХрд░ рдпрд╛ рдЖрд╡рд╛рдЬрд╝ рдореЗрдВ рд╕рд╡рд╛рд▓ рдкреВрдЫ рд╕рдХрддреЗ рд╣реИрдВ!</em></p>
</div>
""", unsafe_allow_html=True)



st.subheader("ЁЯОд рдЖрд╡рд╛рдЬрд╝ рд╕реЗ рд╕рд╡рд╛рд▓ рдкреВрдЫреЗрдВ")
st.caption("рдЕрдкрдиреА рдЖрд╡рд╛рдЬрд╝ рдХреА рдлрд╝рд╛рдЗрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ (WAV/MP3)")

col1, col2 = st.columns([1, 2])
with col1:
    pass
with col2:
   
   audio_file = st.file_uploader("рдЕрдкрдиреА рдЖрд╡рд╛рдЬрд╝ рдлрд╝рд╛рдЗрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ", type=["wav", "mp3" , "jpeg", "png", "jpg"])
   from predictor import predict_disease  # Make sure you import your predictor
   from llm import get_llm_response, tool_search_tomato_kb  # LLM + KM tool import

if audio_file is not None:
    if audio_file is not None and audio_file.type in ["audio/wav", "audio/mpeg", "audio/mp3"]:
        wav_audio_data = audio_file.read()
        if wav_audio_data != st.session_state.get("last_audio_data"):
            st.session_state["last_audio_data"] = wav_audio_data
            st.audio(wav_audio_data, format="audio/wav" if audio_file.type=="audio/wav" else "audio/mp3")
            
            if not st.session_state.get("processing", False):
                st.session_state.processing = True
                try:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                        tmp_file.write(wav_audio_data)
                        tmp_file.flush()
                        tmp_path = tmp_file.name
                    
                    try:
                        voice_text = st.session_state.stt.transcribe_audio(tmp_path, language="hi")
                    finally:
                        if os.path.exists(tmp_path):
                            os.unlink(tmp_path)
                    
                    if voice_text and voice_text.strip():
                        st.info(f"ЁЯУЭ **рдЖрдкрдиреЗ рдХрд╣рд╛:** {voice_text}")
                        
                        with st.spinner("ЁЯдЦ рдЬрд╡рд╛рдм рддреИрдпрд╛рд░ рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
                            response = get_llm_response(voice_text)
                        
                        st.success(f"ЁЯдЦ {response}")
                        
                        st.session_state.chat_history.append({
                            "role": "user",
                            "content": voice_text,
                            "type": "voice",
                            "timestamp": datetime.now().isoformat()
                        })
                        st.session_state.chat_history.append({
                            "role": "assistant",
                            "content": response,
                            "type": "text",
                            "timestamp": datetime.now().isoformat()
                        })
                        
                        if st.session_state.get("voice_enabled", False):
                            with st.spinner("ЁЯОз рдЖрд╡рд╛рдЬрд╝ рддреИрдпрд╛рд░ рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
                                try:
                                    audio_bytes = st.session_state.tts_system.generate_audio(response)
                                    if audio_bytes:
                                        st.audio(audio_bytes, format="audio/mp3")
                                        st.success("ЁЯФК рддреИрдпрд╛рд░!")
                                except Exception as tts_error:
                                    logger.warning(f"TTS failed: {tts_error}")
                                    st.info("ЁЯТб рдЯреЗрдХреНрд╕реНрдЯ рдкрдврд╝реЗрдВ")
                    else:
                        st.warning("тЪая╕П рдЖрд╡рд╛рдЬрд╝ рд╕реНрдкрд╖реНрдЯ рдирд╣реАрдВ рдереА")
                        
                except Exception as e:
                    st.error(f"тЭМ рддреНрд░реБрдЯрд┐: {str(e)}")
                    logger.error(f"Voice error: {e}", exc_info=True)
                finally:
                    st.session_state.processing = False
        # ЁЯОд Valid audio - as before (keep your existing audio logic)

    elif audio_file.type in ["image/jpeg", "image/png", "image/jpg"]:
        st.warning("тЪая╕П рдЖрдкрдиреЗ рдЖрд╡рд╛рдЬрд╝ рдХреА рдЬрдЧрд╣ рдЫрд╡рд┐ рдЕрдкрд▓реЛрдб рдХреА рд╣реИ!")
        st.info("ЁЯУ╕ рд╣рдо рдЗрд╕реЗ рдЯрдорд╛рдЯрд░ рдХреА рдкрддреНрддреА рдХреА рдЫрд╡рд┐ рдорд╛рдирдХрд░ рд░реЛрдЧ рдкрд╣рдЪрд╛рди рд░рд╣реЗ рд╣реИрдВ...")

        img = Image.open(audio_file)

        with st.spinner("ЁЯФН рдЯрдорд╛рдЯрд░ рд░реЛрдЧ рдХреА рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░ рд░рд╣реЗ рд╣реИрдВ..."):
            with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_file:
              tmp_file.write(audio_file.read())
              img_path = tmp_file.name

    with st.spinner("ЁЯФН рдЯрдорд╛рдЯрд░ рд░реЛрдЧ рдЦреЛрдЬ рд░рд╣реЗ рд╣реИрдВ..."):
        # тЬЕ Invoke the ML tool + LLM together
        agent = get_agent()
        result = agent.invoke({
            "messages": [
                {
                    "role": "user",
                    "content": f"рдХреГрдкрдпрд╛ рдЗрд╕ рдЫрд╡рд┐ рд╕реЗ рд░реЛрдЧ рдкрд╣рдЪрд╛рдиреЗрдВ рдФрд░ рдЙрдкрдЪрд╛рд░ рд╕реБрдЭрд╛рдПрдВред рдЫрд╡рд┐ рдкрде: {img_path}"
                }
            ]
        })
        with st.spinner("ЁЯдЦ рд╡рд┐рд╢реЗрд╖рдЬреНрдЮ рд╕рд▓рд╛рд╣ рд▓реЗ рд░рд╣реЗ рд╣реИрдВ..."):
            llm_response = result["messages"][-1].content
     
         
        # Show response in chat
        with st.chat_message("assistant"):
            st.markdown(f"ЁЯдЦ {llm_response}")

        # Optional TTS
        if st.session_state.voice_enabled:
            audio_bytes = st.session_state.tts_system.generate_audio(llm_response)
            if audio_bytes:
                st.audio(audio_bytes, format="audio/mp3")

        # Save to history
     

           

       

      


# ------------------- Enhanced Text Input Section -------------------


# Handle chat input

if user_input := st.chat_input("тЬНя╕П рдЕрдкрдирд╛ рд╕рд╡рд╛рд▓ рдпрд╣рд╛рдБ рд▓рд┐рдЦреЗрдВ... (рдордВрдбреА рднрд╛рд╡ рдкреВрдЫрдиреЗ рдХреЗ рд▓рд┐рдП: 'рдЧреЗрд╣реВрдВ рдХрд╛ рднрд╛рд╡ рдХреНрдпрд╛ рд╣реИ?')"):
    process_text_input(user_input)

# ------------------- Enhanced Footer Section -------------------

# Footer
st.markdown("""
<div style='text-align: center; color: #666; margin-top: 2rem; padding: 1rem; border-top: 1px solid #ddd;'>
    <p>ЁЯМ╛ <strong>AI рдХреГрд╖рд┐ рд╕рд╣рд╛рдпрдХ (By AgroMind)</strong> - рдЖрдкрдХреЗ рдЦреЗрдд рдХрд╛ рдбрд┐рдЬрд┐рдЯрд▓ рдорд┐рддреНрд░</p>
    <p><small>рд╕рдВрд╕реНрдХрд░рдг 3.0 | рдордВрдбреА рднрд╛рд╡ рд╕реБрд╡рд┐рдзрд╛ рдЬреЛрдбрд╝реА рдЧрдИ!</small></p>
    <p><small>Powered by Groq AI, Data.gov.in, SoilGrids & WeatherAPI</small></p>
</div>
""", unsafe_allow_html=True)
